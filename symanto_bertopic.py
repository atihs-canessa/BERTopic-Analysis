# -*- coding: utf-8 -*-
"""Symanto BERTopic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kXUKblPw5qd4lMldlKjZZpTAzvkzwNEu
"""

!pip install bertopic
!pip install bertopic[visualization]
import pandas as pd
import re
from bertopic import BERTopic

data = pd.ExcelFile("/content/Symmantooutput Big.xlsx")
dataframe = pd.ExcelFile.parse(data)
dataframe.columns = ['Brand', 'Date','Date_Group','URL','Snippet','Source']
# dataframe.drop('NONE',axis=1,inplace=True)
dataframe.drop('URL',axis=1,inplace=True)

dataframe.reset_index(drop=True, inplace=True)
# dataframe.set_index('Brand', inplace=True)
dataframe
# dataframe.to_csv('SymDataFrame.csv')

dataframe['Date'] = pd.to_datetime(dataframe["Date"])

dataframe['Snippet'] = dataframe['Snippet'].apply(lambda x: x[3:-3] if '...' in x else x)

dataframe

dataframe['Snippet'] = dataframe['Snippet'].apply(lambda x: re.split(r"(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|!)\s", x))
df = dataframe.explode('Snippet')
df.reset_index(inplace = True, drop = True)
df

df['Date'] = pd.to_datetime(df["Date"])
df['Date'] = df['Date'].dt.date
df

df_ikea = df[df['Brand']=='Ikea']
df_ikea



model = BERTopic(min_topic_size=100, low_memory=True)
topics, probabilities = model.fit_transform(df_ikea['Snippet'])

#############
#############
#Option to chnage the number of topic clusters
new_topics, new_probs = model.reduce_topics(df['Snippet'], topics, probabilities, nr_topics=100)
#############
#############

# before running topics over time need to take the model dataframe into a fromat where dates are in weekly groups to help with time efficiency 

df_ikea['Date'] = pd.to_datetime(df_ikea["Date"])
df_ikea_w
df_ikea['week_start'] = df_ikea['Date'] - df_ikea['Date'].dt.weekday.astype('timedelta64[D]')

df_ikea

topics_over_time = model.topics_over_time(df_ikea['Snippet'], topics, df_ikea['week_start'])

# topics_over_time.set_index("Timestamp", inplace = True)
topics_over_time.index = pd.to_datetime(topics_over_time.index)

# topics_over_time
topics_over_time.groupby(by=['Timestamp','Topic']).sum()

grouper = topics_over_time.groupby(by='Topic')
# grouper
# for k, v in grouper:
#   print(k)
#   print(v['Frequency'])
#   print()
  
df1 = pd.concat([pd.Series(v['Frequency'], name=k) for k, v in grouper], axis=1)
# topics_over_time
df1



grouper = topics_over_time.groupby(by='Topic')
df1 = pd.concat([pd.Series(v['Frequency'], name=k) for k, v in grouper], axis=1)
df1_weekly = df1.resample('W-MON').sum()
df1_weekly.sort_index()
df1

df1

df1_weekly.to_csv('df1wkly.csv')